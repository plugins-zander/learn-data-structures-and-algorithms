# 时间复杂度（问题的规模）

## 概述

　　一个特定算法的“运行工作量”的大小，只依赖于问题的规模（通常用整数量n表示），或者说，它是问题规模的函数。

　　假如，随着问题规模 n 的增长，算法执行时间的增长率和 f(n) 的增长率相同，则可记作：T (n) = O(f(n)), 称T (n) 为算法的(渐近)时间复杂度。

　　一个算法是由控制结构（顺序、分支和循环3种）和原操作（指固有数据类型的操作）构成的，算法的运行时间取决于两者的综合效果。

​	由于时间复杂度与空间复杂度分别对算法占用的时间和空间资源进行分析,计算方法相似,且空间复杂度分析相对简单一些,因此下面主要讨论时间复杂度。算法的时间复杂度分析主要是分析算法的运行时间,即算法执行所需要的基本操作数。

![](https://raw.githubusercontent.com/ZanderZhao/images/master/img2019/20191225235747.png)

## 一般步骤

分析算法时间复杂度的一般步骤

　　从算法中选取一种对于所研究的问题来说是基本操作的原操作，以该基本操作 在算法中重复执行的次数 作为算法运行时间的衡量准则。

　　“基本操作” 指的是，该操作重复执行次数和算法的运行时间成正比。

　　算法的执行时间=∑原操作(i)的执行次数×原操作(i)的执行时间

　　详细算法的执行时间与原操作执行次数之和成正比

　　算法= 控制结构+ 原操作（固有数据类型的操作）

![](https://raw.githubusercontent.com/ZanderZhao/images/master/img2019/20191226000056.png)





### 复杂度情况

不同规模的输入所需要的基本操作数是不相同的,例如用同一个排序算法排序100个数和排序10 000个数所需要的基本操作数是不相同的,因此考虑特定输入规模的算法的具体操作数既是不现实的也是不必要的。在算法分析中,可以建立以输入规模n为自变量的函数$T(n)$来表示算法的时间复杂度。

即使对于相同的输入规模,数据分布不相同也影响了算法执行路径的不同,因此所需要的执行时间也不同。根据不同的输入,将算法的时间复杂度分析分为3种情况。

#### (1) 最佳情况

使算法执行时间最少的输入。一般情况下,不进行算法在最佳情况下的时间复杂度分析。应用最佳情况分析的一个例子是已经证明基于比较的排序算法的时间复杂度下限为 $\Omega (nlgn)$那么就不需要白费力气去想方设法将该类算法改进为线性时间复杂度的算法。

#### (2) 最坏情况

使算法执行时间最多的输入。一般会进行算法在最坏时间复杂度的分析,因为最坏情况是在任何输入下运行时间的一个上限,它给我们提供一个保障,实际情况不会比这更糟糕。另外,对于某些算法来说,最坏情况还是相当频繁的。而且对于许多算法来说,平均情况通常与最坏情况下的时间复杂度一样。

#### (3) 平均情况

算法的平均运行时间,一般来说,这种情况很难分析。举个简单的例子,现要排序10个不同的整数,输入就有10!种不同的情况,平均情况的时间复杂度要考虑每一种输入及其该输入的概率。平均情况分析可以按以下3个步骤进行。

+ 1 将所有的输入按其执行时间分类。
+ 2 确定每类输入发生的概率。
+ 3 确定每类输入的执行时间。

下式给出了 一般算法在平均情况下的复杂度分析。
$$
T(n)= \sum_{i=1}^{m}p_i \times t_i
$$

​	其中,仍$p_i$表示第i类输入发生的概率; $t_i$表示第i类输入的执行时间,输入分为m类。

　　设一个算法的输入规模为n，Dn是所有输入的集合，任一输入I∈Dn，P(I)是I出现的概率，有ΣP(I) =1，T(I)是算法在输入I下所执行的基本语句次数，则该算法的平均执行时间为：A(n)=$\sum_{I\in D_n}P(I)*T(I)$。　　

　　也就是说算法的平均情况是指用各种特定输入下的基本语句执行次数的带权平均值。

　　算法的最好情况为：G(n)=$MIN_{I\in D_n}{T(I)}$，是指算法在所有输入I下所执行基本语句的最少次数。

　　算法的最坏情况为：W(n)=$MAX_{I\in D_n}{T(I)}$，是指算法在所有输入I下所执行基本语句的最大次数。

### 渐进符号

以输入规模n为自变量建立的时间复杂度实际上还是较复杂的,例如$an^2+bn+c$ ,不仅与输入规模有关,还与系数a、b、和c 有关。此时可以对该函数做进一步的抽象,仅考虑运行时间的增长率或称为增长的量级,如忽略上式中的低阶项和髙阶项的系数,仅考虑$n^2$。当输入规模大到只有与运行时间的增长量级有关时,就是在研究算法的渐进效率。也就是说,从极限角度看,只关心算法运行时间如何随着输入规模的无限增长而增长。下面简单介绍3种常用的标准方法来简化算法的渐进分析。

#### (1) $O$记号

+ 定义为:

  给定一个函数$g(n)$,$O(g(n))$={f(n): 存在正常数c和$n_0$,使得对所有的$n \ge n_0$,有$0 \le f(n) \le cg(n)\}$

如图下图 ( a )所示。$O( g ( n ))$表示一个函数集合,往往用该记号给出一个算法运行时间的渐进上界。

　（大O符号），f(n)=O(g(n))（读作“f(n)是g(n)的大O”）当且仅当存在正常量c和n0，使当n≥n0时，f(n)≤cg(n)，即g(n)为f(n)的上界。



```
　如3n+2=O(n)，因为当n≥2时，3n+2≤4n。
　10n^2+4n+2=O(n^4)，因为当n≥2时，10n^2+4n+2≤10n^4。
```

　　大O符号用来描述增长率的上界，表示f(n)的增长最多像g(n) 增长的那样快，也就是说，当输入规模为n时，算法消耗时间的最大值。这个上界的阶越低，结果就越有价值，所以，对于$10n^2+4n+2$，O(n^2^)比O(n^4^) 有价值。

　　一个算法的时间用大O符号表示时，总是采用最有价值的g(n)表示，称之为“紧凑上界”或“紧确上界”。

　　一般地，如果$f(n)=a_mn^m+a_{m-1}n^{m-1}+...+a_1n+a_0$有$f(n)= O(n^m)$

在难以精确计算基本操作执行次数（或语句频度）的情况下，只需求出它关于n的增长率或阶即可2.一个算法的时间复杂度可以具体分为最好、最差（又称最坏）和平均三种情况讨论。

除特别说明外，正常均指最坏情况下的时间复杂度。

$O(log_2n)<O(n)<O(n*log_2n)<O(n^2)<O(n^3)<O(2^n)<O(n!)$







#### (2) $\Omega$记号

定义为:

给定一个函数$g(n)$,$\Omega(g(n))$=\{f(n): 存在正常数c和$n_0$,使得对所有的$n \ge n_0$,有$0 \le cg(n) \le f(n)\}$

如图下图 ( b )所示。$\Omega( g ( n ))$表示一个函数集合,往往用该记号给出一个算法运行时间的渐进下界。

（大Ω符号），f(n)= Ω(g(n))（读作“f(n)是g(n)的大Ω”）当且仅当存在正常量c和nθ，使当n≥n0时，f(n)≥cg(n)，即g(n)为f(n)的下界。

　　如3n+2=Ω(n)，因为当n≥1时，3n+2≥3n。
　　10n2+4n+2=Ω(n2)，因为当n≥1时，10n2+4n+2≥n2。　　

　　大Ω符号用来描述增长率的下界，表示f(n)的增长最少像g(n) 增长的那样快，也就是说，当输入规模为n时，算法消耗时间的最小值。
与大O符号对称，这个下界的阶越高，结果就越有价值，所以，对于10n2+4n+2，Ω(n2)比Ω(n) 有价值。一个算法的时间用大Ω符号表示时，总是采用最有价值的g(n)表示，称之为“紧凑下界”或“紧确下界”。

　　一般地，如果$f(n)=a_mn^m+a_{m-1}n^{m-1}+...+a_1n+a_0$有$f(n)= \Omega(n^m)$













#### (3) $\Theta$记号

- 定义为:

给定一个函数$g(n)$,$\Theta(g(n))$=\{f(n): 存在正常数$c_1$、$c_2$和$n_0$,使得对所有的$n \ge n_0$,有$0 \le c_1g(n) \le f(n)\}$

如图下图 ( a )所示。$\Theta( g ( n ))$表示一个函数集合,往往用该记号给出一个算法运行时间的渐进上界和渐进下届，即渐进紧致界。

（大Θ符号），f(n)= Θ(g(n))（读作“f(n)是g(n)的大Θ”）当且仅当存在正常量c1、c2和n0，使当n≥n0时，有c1g(n)≤f(n)≤c2g(n)，即g(n)与f(n)的同阶。

　　如3n+2=Θ (n)，10n2+4n+2=Θ(n2)。

　　一般地，如果![img](https://img2018.cnblogs.com/blog/1427277/201909/1427277-20190909122659601-634533334.png)，有f(n)=Θ(nm)。

　　大Θ符号比大O符号和大Ω符号都精确，f(n)=Θ(g(n)，当且仅当g(n)既是f(n)的上界又是f(n)的下界。

 

 



![](https://raw.githubusercontent.com/ZanderZhao/images/master/img2019/20191103195939.png)

<center>记号的用例图</center>

由上述定义可知，$f(n)=\Theta(g(n))$当且仅当$f(n)=O(g(n))$和$f(n)=\Omega(g(n))$



![](https://raw.githubusercontent.com/ZanderZhao/images/master/img2019/20191103201737.png)









## 算法选用的策略

### 非递归算法的时间复杂度分析

　　对于非递归算法，分析其时间复杂度相对比较简单，关键是求出代表算法执行时间的表达式。
　　通常是算法中基本语句的执行次数，是一个关于问题规模n的表达式，然后用渐进符号来表示这个表达式即得到算法的时间复杂度。

```c
两个矩阵相乘
void mult(inta[], int b[], int&c[] ) {
// 以二维数组存储矩阵元素，c为 a 和 b的乘积
    for (i=1; i<=n; ++i){ 
        for(j=1; j<=n; ++j) { 
            c[i,j] = 0; 
            for(k=1; k<=n; ++k) 
                c[i,j] += a[i,k]*b[k,j];  //基本操作: 乘法操作
            } 
    }
} //时间复杂度:  O(n^3)    
```

```c
选择排序
//将a中整数序列重新排序成自小到大有序的整数序列
void select_sort(int& a[],int n){
	for(i=0; i<n-1; ++i){
		j=i;//选择第i个最小元素
        for(k=i+1; k<n; ++k){
        	if(a[k]<a[j]){		//基本操作：比较数据元素操作
        		j=k;
        	}
            if(j != i){
            	a[j]<-->a[i]
            }
        }
	}
}//时间复杂度O(n^2)
```

```c
冒泡排序
//将a中整数序列重新排序成自小到大有序的整数序列
void bubble_sort(int& a[],int n){
	for(i=n-1,change=TRUE; i>1 &&change; --i){
		change = FALSE; //change为元素进行交换标志
		for(j=0; j<i; ++j){
        	if(a[j]>a[j+1]){
        		a[j]<-->a[j+1];	//基本操作：赋值操作
        		change = TRUE;
        	}
		}//一趟起泡
	}
}//时间复杂度O(n^2)
```

```c
给出以下算法的时间复杂度。
void func(int n)
{   int i=1,k=100;
    while (i<=n)
    {  k++;
       i+=2;
    }
}
　　解：算法中基本语句是while循环内的语句。
       设while循环语句执行的次数为m，i从1开始递增，最后取值为1+2m，有：
       i=1+2m≤n
       f(n)=m≤(n-1)/2=O(n)。
　　该算法的时间复杂度为O(n)。
```











### 递归算法的时间复杂度分析

　　递归算法是采用一种分而治之的方法，把一个“大问题”分解为若干个相似的“小问题”来求解。
　　对递归算法时间复杂度的分析，关键是根据递归过程建立递推关系式，然后求解这个递推关系式，得到一个表示算法执行时间的表达式，最后用渐进符号来表示这个表达式即得到算法的时间复杂度。

```c
有如下递归函数fact(n)，分析其时间复杂度
int fact(int n){ 
	if(n<=1)
    	return(1);          //    (1) 
	else
    	return(n*fact(n-1));    //    (2）
}
解：设fact(n)的运行时间复杂函数是T(n)，
     该函数中语句(1)的运行时间是O(1),
     语句(2)的运行时间为：T(n-1)+O(1),
     其中O(1)为基本运算时间，
因此：  T(n) = O(1)+T(n-1)
            = O(1)+O(1)+T(n-2)
            = …… 
            = (n-1)*O(1)+T(1) 
            = n*O(1) 
            = O(n)则fact(n)的时间复杂度为O(n)。
```



```c
有以下递归算法：
void mergesort(int a[],int i,int j)
{   int m;
    if (i!=j)
    {     m=(i+j)/2;
        mergesort(a,i,m);
        mergesort(a,m+1,j);
        merge(a,i,j,m);
    }
}
    其中，mergesort()用于数组a[0..n-1]（设n=2k，这里的k为正整数）的归并排序，　　调用该算法的方式为：
      mergesort(a，0，n-1)；
    另外merge(a，i，j，m)用于两个有序子序列a[i..j]和a[j+1..m]的有序合并，　　是非递归函数，它的时间复杂度为O(n)（这里n=j-i+1）。分析上述调用的时间复杂度。
    
解：设调用mergesort(a，0，n-1)的执行时间为T(n)，由其执行过程得到以下求执行时间的递归关系（递推关系式）：
T(n)=O(1)        当n=1
T(n)=2T(n/2)+O(n)    当n>1
其中，O(n)为merge()所需的时间，设为cn（c为正常量）。因此：
T(n) = 2T(n/2)+cn=2[2T(n/22)+cn/2]+cn=22T(n/22)+2cn
     = 23T(n/23)+3cn
     = …
     = 2kT(n/2k)+kcn
     = nO(1)+cnlog2n=n+cnlog2n    //这里假设n=2k，则k=log2n
     = O(nlog2n)

```



```c
求解梵塔问题的递归算法如下，分析其时间复杂度。
void Hanoi(int n,char x,char y,char z)
{  if (n==1)
      printf("将盘片%d从%c搬到%c\n",n,x,z);
   else
   {   Hanoi(n-1,x,z,y);
       printf("将盘片%d从%c搬到%c\n",n,x,z);
       Hanoi(n-1,y,x,z);
   }
}

设调用Hanoi(n，x，y，z)的执行时间为T(n)，由其执行过程得到以下求执行时间的递归关系（递推关系式）：
T(n)=O(1)      当n=1
T(n)=2T(n-1)+1      当n>1
T(n) = 2[2T(n-2)+1]+1+1
     = 2*2T(n-2)+1+2*1
     = 2^2*T(n-2)+1+2*1   //T(n-2)=2(T(n-3))+1
     = 2^2*(2(T(n-3))+1)+1+2*1
     = 2^2*(2(T(n-3))+1)+1+2*1
     = 2^3*T(n-3)+2*2+1+2*1 
//第二次  = 2^2*T(n-2) + 1 + 2*1
//第三次  = 2^3*T(n-3) + 1 + 2*1 + 2*2  
//第n次   = 2^n*T(n-n) + 1 + 2^1 + 2^2  + 2^3 + ... + 2^(n-1)  n不能为0，向前推一个
//第n-1次 = (2^(n-1)) * T(n-(n-1)) + 1 + 2^1 + 2^2  + 2^3 + ... + 2^(n-2)  n不能为0，向前推一个
//        = (2^(n-1)) * T(1) + 1 + 2^1 + 2^2  + 2^3 + ... + 2^(n-2) 
//        = (2^(n-1)) * O(1)    [+ 1 + 2^1 + 2^2  + 2^3 + ... + 2^(n-2)]后面阶比n-1小忽略不计    
     = …
     = (2^(n-1))*T(1)+1+2^1+2^2+…+2^(n-2)
     = 2^(n-1) = O(2^n)
```

